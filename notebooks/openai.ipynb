{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854488f2",
   "metadata": {},
   "source": [
    "# üöÄ OpenAI Python SDK 101\n",
    "\n",
    "In this notebook we‚Äôll learn how to interact with Large Language Models (LLMs) directly using the **OpenAI Python SDK**.  \n",
    "This is the **first time** we‚Äôre exploring API interactions, so we‚Äôll build up gradually:\n",
    "\n",
    "1. **Initialize** the client with your API key.  \n",
    "2. **Minimal call** to the API (Responses API).  \n",
    "3. Use **Chat Completions** for system + user roles.  \n",
    "4. Explore **temperature** (randomness) and **top_p** (nucleus sampling).  \n",
    "5. Add **system prompts** to guide behavior.  \n",
    "6. Try **streaming tokens** (like ChatGPT typing).  \n",
    "7. Get **JSON/structured outputs** with schemas.  \n",
    "8. Handle **errors, timeouts, and retries** gracefully.\n",
    "\n",
    "By the end, you‚Äôll know how to **call an LLM safely and flexibly** using just the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844e5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf239a",
   "metadata": {},
   "source": [
    "### API key\n",
    "- Set your OpenAI API key as an environment variable:  \n",
    "  `export OPENAI_API_KEY=\"sk-...\"` (macOS/Linux) or `setx OPENAI_API_KEY \"sk-...\"` (Windows, new terminal required).  \n",
    "- In Colab: use `os.environ[\"OPENAI_API_KEY\"] = \"...\"` (for demos only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e911ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Python SDK v1 style\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature controls the randomness of the predictions (lower values make the output more deterministic), while top_p (nucleus sampling) limits the selection to a subset of the probable outcomes based on cumulative probability, ensuring a more varied output.\n"
     ]
    }
   ],
   "source": [
    "# Minimal \"Responses API\" call (recommended by OpenAI for new projects)\n",
    "# Docs: https://platform.openai.com/docs/guides/text  and Responses vs Chat Completions\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # choose any available text-capable model\n",
    "    input=\"In one sentence, explain the difference between temperature and top_p for sampling.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fd52e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_03e4a62aa4eb21a70068ea715b4410819981981012ad690bed', created_at=1760194907.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_03e4a62aa4eb21a70068ea715c92988199b1892055c325b64d', content=[ResponseOutputText(annotations=[], text='Temperature controls the randomness of the predictions (lower values make the output more deterministic), while top_p (nucleus sampling) limits the selection to a subset of the probable outcomes based on cumulative probability, ensuring a more varied output.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=22, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=46, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=68), user=None, billing={'payer': 'developer'}, store=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff892c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which hinders its performance on unseen data.\n",
      "\n",
      "- **Symptoms**: Indications of overfitting include a low training error coupled with a high validation or test error, suggesting the model is too complex for the given data.\n",
      "\n",
      "- **Prevention**: Techniques to prevent overfitting include using simpler models, regularization methods (e.g., L1 or L2 regularization), cross-validation, and techniques such as dropout in neural networks.\n"
     ]
    }
   ],
   "source": [
    "# Using Chat Completions (still widely used & supported)\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise teaching assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me 3 bullet points about overfitting.\"},\n",
    "    ],\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01254fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CPVR1yklkREZ5BiYRWdVuBxDUU47x', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which hinders its performance on unseen data.\\n\\n- **Symptoms**: Indications of overfitting include a low training error coupled with a high validation or test error, suggesting the model is too complex for the given data.\\n\\n- **Prevention**: Techniques to prevent overfitting include using simpler models, regularization methods (e.g., L1 or L2 regularization), cross-validation, and techniques such as dropout in neural networks.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760195071, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=116, prompt_tokens=29, total_tokens=145, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5dddecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's a simple example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "!dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python tutor who answers with short code examples.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Show how to reverse a string in Python.\"}\n",
    "]\n",
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=0)\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63fd12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's a simple example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "```\n",
      "!dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=1)\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "553e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a sun-drenched little village, there lived a cat named Whiskers and a dog named Barkley. They resided in neighboring houses, separated by a low wooden fence that, for years, had kept them apart. Whiskers was a sleek, gray tabby with a penchant for climbing trees and basking in the sunlight, while Barkley was a jovial golden retriever with boundless energy and a love for chasing after anything that moved.\n",
      "\n",
      "The two animals had seen each other from a distance but had never exchanged a word. Whiskers would often watch Barkley romp through the yard, chasing butterflies and wagging his tail, while Barkley admired Whiskers perched on a branch, her eyes gleaming in the afternoon sun. Despite their differences, a spark of curiosity flickered between them.\n",
      "\n",
      "One fateful afternoon, a powerful storm swept through the village, bringing with it heavy rain and howling winds. Whiskers, frightened and seeking shelter, climbed down from her tree and darted toward the safety of her home. But as she scurried past the fence, she heard a frantic barking. It was Barkley, trying to squeeze his way through a gap in the fence, barking wildly as he searched for a place to escape the storm.\n",
      "\n",
      "‚ÄúHey! You‚Äôll get stuck!‚Äù Whiskers called out, her heart racing with concern. \n",
      "\n",
      "Barkley paused, his wet fur glistening like gold in the dim light. ‚ÄúI just want to get to safety! Do you know anywhere we can hide?‚Äù\n",
      "\n",
      "Whiskers thought for a moment. ‚ÄúFollow me!‚Äù she said, leading him around the house to the back porch, where a small shed stood. It was old and filled with gardening tools, but it was dry.\n",
      "\n",
      "Together, they squeezed into the shed just as the storm reached its peak. The wind howled, and rain pelted the roof, but inside the shed, they found a moment of calm. As they huddled together, Barkley looked at Whiskers with wide, grateful eyes. ‚ÄúThank you for helping me. I‚Äôve always wanted to meet you, but I didn‚Äôt know how.‚Äù\n",
      "\n",
      "Whiskers purred softly, feeling warmth spread through her. ‚ÄúI‚Äôve watched you from afar. You seem like a lot of fun.‚Äù\n",
      "\n",
      "As the storm raged outside, they shared stories about their lives. Whiskers told Barkley about her adventures climbing the tallest trees, while Barkley regaled Whiskers with tales of his escapades chasing squirrels and playing fetch. They laughed and shared secrets, and soon the storm didn‚Äôt seem so frightening anymore.\n",
      "\n",
      "When the skies finally cleared and the sun peeked out, they emerged from the shed, both soggy but smiling. The world looked different now, transformed by the storm. Barkley wagged his tail, splattering mud everywhere, while Whiskers shook off the rain, her fur fluffing up like a cloud.\n",
      "\n",
      "‚ÄúWanna race to the tree?‚Äù Barkley challenged, his eyes sparkling with excitement.\n",
      "\n",
      "Whiskers, feeling playful, accepted. ‚ÄúYou‚Äôre on!‚Äù\n",
      "\n",
      "With a burst of energy, they dashed across the yard, the barriers of the past forgotten. They raced, barked, and purred with joy, their laughter echoing through the village. From that day on, Whiskers and Barkley were inseparable, exploring the world together, each adventure building a bond that neither of them had ever expected.\n",
      "\n",
      "And so, a cat and a dog became the best of friends, proving that sometimes a storm can lead to the brightest of friendships.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import stdout\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a cat and a dog.\"}],\n",
    "    temperature=0.7,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, \"choices\"):\n",
    "        delta = event.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            stdout.write(delta.content)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd5925f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"item\": \"Rice\",\n",
      "        \"quantity\": \"3 kg\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Dhal\",\n",
      "        \"quantity\": \"4 kg\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Biscuits\",\n",
      "        \"quantity\": \"3 packets\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Sugar\",\n",
      "        \"quantity\": \"2 kg\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I have bought 3 kg of Rice, 4 kg of dhal, 3 packets of biscuits, 2 kg of sugar.\n",
    "\n",
    "Format this as a list of json objects with each JSON object in the following format:\n",
    "{\n",
    "    \"item\": \"item name\",\n",
    "    \"quantity\": \"quantity\"\n",
    "}\n",
    "\n",
    "DO NOT include anything else in your response.\"\"\"\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1c926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "\n",
    "items = json.loads(response)\n",
    "type(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55e11846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice\n",
      "Dhal\n",
      "Biscuits\n",
      "Sugar\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    print(item[\"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a7efd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(topic='Transformers in NLP', key_points=['Transformers utilize self-attention mechanisms to weigh the importance of different words in a sentence, allowing for better context understanding.', 'They enable parallel processing of data, significantly speeding up training times compared to previous sequential models like RNNs and LSTMs.', 'Transformers have led to the development of powerful pre-trained models (e.g., BERT, GPT) that can be fine-tuned for various NLP tasks, achieving state-of-the-art results.'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    topic: str\n",
    "    key_points: List[str]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    response_format=Summary,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Topic: Transformers in NLP. Give 3 key points.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsed = completion.choices[0].message.parsed\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "334e5e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Summary"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad6d077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items=[ShoppingItem(item='Rice', quantity=3), ShoppingItem(item='Dhal', quantity=4), ShoppingItem(item='Biscuits', quantity=3), ShoppingItem(item='Sugar', quantity=2)]\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I have bought 3 kg of Rice, 4 kg of dhal, 3 packets of biscuits, 2 kg of sugar.\"\"\"\n",
    "\n",
    "\n",
    "class ShoppingItem(BaseModel):\n",
    "    item: str\n",
    "    quantity: int\n",
    "\n",
    "class ShoppingList(BaseModel):\n",
    "    items: List[ShoppingItem]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    response_format=ShoppingList,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b0878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShoppingList(items=[ShoppingItem(item='Rice', quantity=3), ShoppingItem(item='Dhal', quantity=4), ShoppingItem(item='Biscuits', quantity=3), ShoppingItem(item='Sugar', quantity=2)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3afffb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"items\":[{\"item\":\"Rice\",\"quantity\":3},{\"item\":\"Dhal\",\"quantity\":4},{\"item\":\"Biscuits\",\"quantity\":3},{\"item\":\"Sugar\",\"quantity\":2}]}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
